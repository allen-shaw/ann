{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10674c7d",
   "metadata": {},
   "source": [
    "# LSH（Locality-Sensitive Hashing）\n",
    "\n",
    "## 核心思想\n",
    "目的：在高维空间中快速找到“相似”的数据点。\n",
    "\n",
    "关键思想：让相似的样本在哈希后 落入同一个桶（bucket） 的概率高，不相似的样本落入同桶的概率低。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a3356",
   "metadata": {},
   "source": [
    "## 算法原理\n",
    "\n",
    "### 1. 构建随机超平面（Random Hyperplanes）\n",
    "\n",
    "在d维空间随机生成k个向量 (r1, r2, ... , rk)  shape(k, d)\n",
    "\n",
    "每个向量的分布服从标准正态分布N(0,1)\n",
    "\n",
    "### 2. 计算Hash签名（Hash Signature）\n",
    "\n",
    "对于一个向量x, 计算h(x) -> 1/0\n",
    "\n",
    "h_i(x) = 1 if r_i * x >= 0\n",
    "\n",
    "x与超平面相乘，如果为整数，说明两个向量角度相似，返回1\n",
    "\n",
    "每个超平面的结果拼接成一个二进制串（如 10100110）， 这就是该向量的 哈希签名\n",
    "\n",
    "### 3. 构建多个Hash表\n",
    "\n",
    "有L组Hash表\n",
    "\n",
    "每组有k个hash函数组成一个hash tablc \n",
    "\n",
    "每个样本被插入到 L 个不同表中，从而提升召回率。\n",
    "\n",
    "k = 10~20\n",
    "L = 20~100 \n",
    "\n",
    "### 4. 查询(Query)\n",
    "\n",
    "给定查询向量q\n",
    "\n",
    "1. 计算其在每个哈希表中的签名（每个hash表有k个hash函数）\n",
    "2. 找出所有桶中与其哈希相同的候选样本\n",
    "3. 对候选样本计算真实相似度（如余弦或欧式距离）c\n",
    "4. 返回最相似的 Top-K\n",
    "\n",
    "### 5. 算法复杂度\n",
    "\n",
    "建表： 时间复杂度O(n*k*L)\n",
    "查询： 时间复杂度O(L*(k+c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3ad021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Union, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6898a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineLSH:\n",
    "    '''\n",
    "    基于 随机超平面投影 的 局部敏感哈希(LSH) \n",
    "    适用于余弦相似度测量\n",
    "\n",
    "    参数:\n",
    "    - hash_size(int): 单个哈希表的哈希函数数量\n",
    "    - num_tables(int): 使用的哈希表数量\n",
    "    '''\n",
    "    def __init__(self, hash_size: int=6, num_tables: int=5, dim=None) -> None:\n",
    "        self.hash_size = hash_size      # 每个哈希表的位数\n",
    "        self.num_tables = num_tables    # 哈希表数量\n",
    "        self.hash_tables = [dict() for _ in range(num_tables)]\n",
    "        self.random_planes_list = []    # 存储每个哈希表的随机超平面\n",
    "        self.dimension = dim           # 数据维度（在插入数据时确定）\n",
    "\n",
    "    def _generate_random_planes(self, dimension: int) -> np.ndarray:\n",
    "        '''\n",
    "        为每个哈希表生成随机超平面（每一个超平面对应一个哈希函数）\n",
    "        '''\n",
    "        return np.random.randn(self.hash_size, dimension) # shape(hash_size, dimension)\n",
    "  \n",
    "    def _hash(self, vector: np.ndarray, random_planes: np.ndarray) -> str:\n",
    "        '''\n",
    "        计算单个向量的hash值（二进制字符串）\n",
    "        '''\n",
    "        projections = np.dot(vector, random_planes.T)\n",
    "        hash_bits = (projections > 0).astype(int) # 大于0->1, 否则为0\n",
    "        return ''.join(hash_bits.astype(str))\n",
    "\n",
    "    def index(self, data) -> None:\n",
    "        '''\n",
    "        将数据向量插入到LSH索引中\n",
    "        \n",
    "        参数:\n",
    "        - data: 待索引的向量列表\n",
    "        '''\n",
    "        data_array = np.array(data)\n",
    "        if len(data_array.shape) == 1:\n",
    "            data_array = data_array.reshape(1, -1) # shepe(dim,0) -> shape(1,dim) 将一个向量转成一个1行矩阵\n",
    "\n",
    "        self.dimension = data_array.shape[1]\n",
    "\n",
    "        # 为每一个hash table生成随机超平面\n",
    "        self.random_planes_list = [\n",
    "            self._generate_random_planes(self.dimension)\n",
    "            for _ in range(self.num_tables)\n",
    "        ]\n",
    "\n",
    "        # 将每一个向量插入所有hash table\n",
    "        for i, vector in enumerate(data_array):\n",
    "            for table_idx in range(self.num_tables):\n",
    "                hash_key = self._hash(vector, self.random_planes_list[table_idx])\n",
    "\n",
    "                # 将向量索引存到对应的hash桶\n",
    "                if hash_key in self.hash_tables[table_idx]:\n",
    "                    self.hash_tables[table_idx][hash_key].append(i)\n",
    "                else:\n",
    "                    self.hash_tables[table_idx][hash_key] = [i]\n",
    "\n",
    "    def query(self, query_vector, max_results = 10) -> List[int]:\n",
    "        '''\n",
    "        查询与给定向量相似的向量\n",
    "\n",
    "        参数:\n",
    "        - query_vector: 查询向量\n",
    "        - max_results: 返回的最大结果数量 top_k\n",
    "\n",
    "        返回:\n",
    "        - 相似向量的索引列表\n",
    "        '''\n",
    "        if self.dimension is None:\n",
    "            raise ValueError('Please Insert Data')\n",
    "\n",
    "        query_vec = np.array(query_vector)\n",
    "        candidates = set()\n",
    "        \n",
    "        # 在所有哈希表中查找候选向量\n",
    "        for table_idx in range(self.num_tables):\n",
    "            hash_key = self._hash(query_vec, self.random_planes_list[table_idx])\n",
    "            if hash_key in self.hash_tables[table_idx]:\n",
    "                candidates.update(self.hash_tables[table_idx][hash_key])\n",
    "\n",
    "        # 如果没有找到候选向量，尝试查找邻近桶\n",
    "        if not candidates:\n",
    "            print('No exact matching candidate vector found; searching neighboring buckets....')\n",
    "\n",
    "            for table_idx in range(self.num_tables):\n",
    "                original_key = self._hash(query_vec, self.random_planes_list[table_idx])\n",
    "                # 查找哈希码只有1位不同的桶\n",
    "                for i in range(self.hash_size):\n",
    "                    neighbor_key = list(original_key)\n",
    "                    neighbor_key[i] = '1' if neighbor_key[i] == '0' else '0'\n",
    "                    neighbor_key = ''.join(neighbor_key)\n",
    "                    if neighbor_key in self.hash_tables[table_idx]:\n",
    "                        candidates.update(self.hash_tables[table_idx][neighbor_key])\n",
    "\n",
    "        return list(candidates)[:max_results]\n",
    "\n",
    "    def get_hash_tables_info(self) -> Dict:\n",
    "        '''\n",
    "        返回哈希表统计信息\n",
    "        '''\n",
    "        info = {\n",
    "            'num_tables': self.num_tables,\n",
    "            'hash_size': self.hash_size,\n",
    "            'total_buckets': 0,\n",
    "            'average_bucket_size': 0,\n",
    "            'table_details': [],\n",
    "            'total_vectors': 0\n",
    "        }\n",
    "\n",
    "        total_vectors = 0\n",
    "        for i, table in enumerate(self.hash_tables):\n",
    "            num_buckets = len(table)  # 有多少个hash_key\n",
    "            vectors_in_table = sum(len(bucket) for bucket in table.values()) # sum(每个key有多少index)\n",
    "            total_vectors += vectors_in_table\n",
    "\n",
    "            average_bucket_size = vectors_in_table / num_buckets if num_buckets > 0 else 0\n",
    "            info['table_details'].append({\n",
    "                'table_index': i,\n",
    "                'num_buckets': num_buckets,\n",
    "                'total_vectors': vectors_in_table,\n",
    "                'average_bucket_size': average_bucket_size\n",
    "            })\n",
    "\n",
    "        info['total_vectors'] = total_vectors\n",
    "        info['total_buckets'] = sum(detail['num_buckets']\n",
    "            for detail in info['table_details']\n",
    "        )\n",
    "\n",
    "        if info['total_buckets'] > 0:\n",
    "            info['average_bucket_size'] = (total_vectors /info['total_buckets'])\n",
    "\n",
    "        return info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb8ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cosine_hash():\n",
    "    np.random.seed(42)\n",
    "    data_vectors = np.random.randn(100, 10) # 100个10维向量 (100, 10)\n",
    "\n",
    "    # 创建LSH索引\n",
    "    print('creating LSH index')\n",
    "    lsh = CosineLSH(hash_size=8, num_tables=3)\n",
    "    lsh.index(data_vectors)\n",
    "\n",
    "    # 显示hash tables 统计信息\n",
    "    info = lsh.get_hash_tables_info()\n",
    "    print(f'\\n哈希表统计信息:')\n",
    "    print(f'哈希表数量: {info['num_tables']}')\n",
    "    print(f'总桶数: {info['total_buckets']}')\n",
    "    print(f'平均每个桶的向量数: {info['average_bucket_size']:.2f}')\n",
    "\n",
    "    # 查询\n",
    "    query_vec = data_vectors[0]\n",
    "    print(f'\\n查询向量索引: 0')\n",
    "\n",
    "    similar_indices = lsh.query(query_vec, max_results=5)\n",
    "    print(f'找到的相似向量索引: {similar_indices}')\n",
    "\n",
    "    # 验证结果：计算实际余弦相似度\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    \n",
    "    print('\\n相似度验证:')\n",
    "    for idx in similar_indices:\n",
    "        similarity = cosine_similarity([query_vec], [data_vectors[idx]])[0][0]\n",
    "        print(f'向量 {idx} 与查询向量的余弦相似度: {similarity:.4f}')\n",
    "\n",
    "    # 对比线性搜索结果\n",
    "    print('\\n=== 与线性搜索对比 ===')\n",
    "    all_similarities = cosine_similarity([query_vec], data_vectors)[0]\n",
    "    top_linear = np.argsort(all_similarities)[::-1][1:6]  # 排除自身，取前5个\n",
    "    print(f'线性搜索Top-5结果: {top_linear}')\n",
    "\n",
    "    # 计算召回率\n",
    "    lsh_recall = len(set(similar_indices) & set(top_linear)) / len(top_linear)\n",
    "    print(f'LSH召回率（与真实Top-5相比）: {lsh_recall:.2%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5fb9290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating LSH index\n",
      "\n",
      "哈希表统计信息:\n",
      "哈希表数量: 3\n",
      "总桶数: 189\n",
      "平均每个桶的向量数: 1.59\n",
      "\n",
      "查询向量索引: 0\n",
      "找到的相似向量索引: [0, 48, 20, 54, 86]\n",
      "\n",
      "相似度验证:\n",
      "向量 0 与查询向量的余弦相似度: 1.0000\n",
      "向量 48 与查询向量的余弦相似度: -0.2653\n",
      "向量 20 与查询向量的余弦相似度: 0.5041\n",
      "向量 54 与查询向量的余弦相似度: 0.4609\n",
      "向量 86 与查询向量的余弦相似度: 0.6143\n",
      "\n",
      "=== 与线性搜索对比 ===\n",
      "线性搜索Top-5结果: [91 32 15 86 20]\n",
      "LSH召回率（与真实Top-5相比）: 40.00%\n"
     ]
    }
   ],
   "source": [
    "run_cosine_hash()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e809a6",
   "metadata": {},
   "source": [
    "理解LSH算法的参数对掌握其工作原理至关重要：\n",
    "\n",
    "1. hash_size（hash码长度）\n",
    "\n",
    "决定每个哈希表的哈希码长度（位数）影响：\n",
    "\n",
    "值越大，哈希桶划分越精细，相似度判断越准确，但每个桶内的向量可能越少\n",
    "\n",
    "2. num_tables (hash表数量)\n",
    "\n",
    "控制使用的独立哈希表数量 影响：值越大，找到真正近邻的概率越高，但内存消耗也会增加\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
